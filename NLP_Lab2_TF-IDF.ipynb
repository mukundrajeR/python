{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d5028e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "875e8c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph=\"\"\"NLTK is a leading \"platform\" for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries, and an active discussion forum.\n",
    "Thanks to a hands-on guide introducing programming fundamentals alongside topics in computational linguistics, plus comprehensive API documentation, NLTK is suitable for linguists, engineers, students, educators, researchers, and industry users alike. NLTK is available for Windows, Mac OS X, and Linux. Best of all, NLTK is a free, open source, community-driven project.\n",
    "NLTK has been called “a wonderful tool for teaching, and working in, computational linguistics using Python,” and “an amazing library to play with natural language.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f93a1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet=WordNetLemmatizer()\n",
    "sentenses=nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0f3bd45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLTK is a leading \"platform\" for building Python programs to work with human language data.',\n",
       " 'It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries, and an active discussion forum.',\n",
       " 'Thanks to a hands-on guide introducing programming fundamentals alongside topics in computational linguistics, plus comprehensive API documentation, NLTK is suitable for linguists, engineers, students, educators, researchers, and industry users alike.',\n",
       " 'NLTK is available for Windows, Mac OS X, and Linux.',\n",
       " 'Best of all, NLTK is a free, open source, community-driven project.',\n",
       " 'NLTK has been called “a wonderful tool for teaching, and working in, computational linguistics using Python,” and “an amazing library to play with natural language.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "212dfec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "for i in range(len(sentenses)):\n",
    "    review=re.sub('[^a-zA-Z]',' ',sentenses[i])\n",
    "    review=review.lower()\n",
    "    review=review.split()\n",
    "    review=[wordnet.lemmatize(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review=' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8de9c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nltk called wonderful tool teaching working computational linguistics using python amazing library play natural language'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15baf794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the Bag of words model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer()\n",
    "X=cv.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64aa5af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0,\n",
       "        1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       "       [0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "        0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "        0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "859824f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the TF-IDF model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "cv=TfidfVectorizer()\n",
    "X=cv.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e56675b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.34085203, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.34085203, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.34085203, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.27950354, 0.34085203, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.1746276 , 0.        , 0.        ,\n",
       "        0.34085203, 0.        , 0.        , 0.        , 0.34085203,\n",
       "        0.        , 0.        , 0.        , 0.27950354, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.34085203, 0.        , 0.        ],\n",
       "       [0.18669687, 0.        , 0.18669687, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.18669687, 0.        , 0.        , 0.        , 0.18669687,\n",
       "        0.        , 0.18669687, 0.        , 0.        , 0.18669687,\n",
       "        0.        , 0.        , 0.18669687, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.18669687, 0.        ,\n",
       "        0.18669687, 0.        , 0.        , 0.        , 0.18669687,\n",
       "        0.30618821, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.18669687, 0.        , 0.        , 0.18669687,\n",
       "        0.        , 0.        , 0.        , 0.18669687, 0.        ,\n",
       "        0.        , 0.        , 0.18669687, 0.        , 0.18669687,\n",
       "        0.        , 0.18669687, 0.18669687, 0.        , 0.18669687,\n",
       "        0.18669687, 0.        , 0.        , 0.18669687, 0.18669687,\n",
       "        0.        , 0.18669687, 0.        , 0.18669687, 0.        ,\n",
       "        0.        , 0.18669687, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.18669687, 0.        , 0.        , 0.18669687],\n",
       "       [0.        , 0.2103175 , 0.        , 0.2103175 , 0.        ,\n",
       "        0.2103175 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.2103175 , 0.17246336, 0.        ,\n",
       "        0.        , 0.        , 0.2103175 , 0.        , 0.        ,\n",
       "        0.2103175 , 0.2103175 , 0.        , 0.        , 0.2103175 ,\n",
       "        0.2103175 , 0.2103175 , 0.        , 0.        , 0.2103175 ,\n",
       "        0.        , 0.2103175 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.2103175 , 0.17246336, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.10775128, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.2103175 , 0.        , 0.        ,\n",
       "        0.2103175 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.2103175 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.2103175 , 0.2103175 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.2103175 , 0.        , 0.        ,\n",
       "        0.2103175 , 0.        , 0.2103175 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.48436069, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.48436069, 0.48436069,\n",
       "        0.        , 0.        , 0.24815093, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.48436069,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.37107147, 0.        , 0.        ,\n",
       "        0.        , 0.37107147, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.37107147, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.37107147, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19010983, 0.37107147, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.37107147, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.37107147, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.28144352,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.28144352,\n",
       "        0.        , 0.        , 0.        , 0.23078771, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.23078771, 0.        , 0.        ,\n",
       "        0.23078771, 0.        , 0.23078771, 0.        , 0.        ,\n",
       "        0.28144352, 0.        , 0.14419104, 0.        , 0.        ,\n",
       "        0.        , 0.28144352, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.23078771, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.28144352, 0.        , 0.        , 0.        , 0.28144352,\n",
       "        0.        , 0.        , 0.        , 0.28144352, 0.        ,\n",
       "        0.28144352, 0.        , 0.        , 0.28144352, 0.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "550388ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\he336\\anaconda3\\lib\\site-packages (4.1.2)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\he336\\anaconda3\\lib\\site-packages (from gensim) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\he336\\anaconda3\\lib\\site-packages (from gensim) (1.21.5)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\he336\\anaconda3\\lib\\site-packages (from gensim) (5.1.0)\n"
     ]
    }
   ],
   "source": [
    "# download gensim library\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "127dcf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating word2vec model\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b97cd781",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph=\"\"\"NLTK is a leading \"platform\" for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries, and an active discussion forum.\n",
    "Thanks to a hands-on guide introducing programming fundamentals alongside topics in computational linguistics, plus comprehensive API documentation, NLTK is suitable for linguists, engineers, students, educators, researchers, and industry users alike. NLTK is available for Windows, Mac OS X, and Linux. Best of all, NLTK is a free, open source, community-driven project.\n",
    "NLTK has been called “a wonderful tool for teaching, and working in, computational linguistics using Python,” and “an amazing library to play with natural language.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e4a71b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "for i in range(len(sentenses)):\n",
    "    review=re.sub('[^a-zA-Z]',' ',sentenses[i])\n",
    "    review=review.lower()\n",
    "    review=review.split()\n",
    "    review=[wordnet.lemmatize(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    #review=' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "411ebe36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['nltk',\n",
       "  'leading',\n",
       "  'platform',\n",
       "  'building',\n",
       "  'python',\n",
       "  'program',\n",
       "  'work',\n",
       "  'human',\n",
       "  'language',\n",
       "  'data'],\n",
       " ['provides',\n",
       "  'easy',\n",
       "  'use',\n",
       "  'interface',\n",
       "  'corpus',\n",
       "  'lexical',\n",
       "  'resource',\n",
       "  'wordnet',\n",
       "  'along',\n",
       "  'suite',\n",
       "  'text',\n",
       "  'processing',\n",
       "  'library',\n",
       "  'classification',\n",
       "  'tokenization',\n",
       "  'stemming',\n",
       "  'tagging',\n",
       "  'parsing',\n",
       "  'semantic',\n",
       "  'reasoning',\n",
       "  'wrapper',\n",
       "  'industrial',\n",
       "  'strength',\n",
       "  'nlp',\n",
       "  'library',\n",
       "  'active',\n",
       "  'discussion',\n",
       "  'forum'],\n",
       " ['thanks',\n",
       "  'hand',\n",
       "  'guide',\n",
       "  'introducing',\n",
       "  'programming',\n",
       "  'fundamental',\n",
       "  'alongside',\n",
       "  'topic',\n",
       "  'computational',\n",
       "  'linguistics',\n",
       "  'plus',\n",
       "  'comprehensive',\n",
       "  'api',\n",
       "  'documentation',\n",
       "  'nltk',\n",
       "  'suitable',\n",
       "  'linguist',\n",
       "  'engineer',\n",
       "  'student',\n",
       "  'educator',\n",
       "  'researcher',\n",
       "  'industry',\n",
       "  'user',\n",
       "  'alike'],\n",
       " ['nltk', 'available', 'window', 'mac', 'o', 'x', 'linux'],\n",
       " ['best', 'nltk', 'free', 'open', 'source', 'community', 'driven', 'project'],\n",
       " ['nltk',\n",
       "  'called',\n",
       "  'wonderful',\n",
       "  'tool',\n",
       "  'teaching',\n",
       "  'working',\n",
       "  'computational',\n",
       "  'linguistics',\n",
       "  'using',\n",
       "  'python',\n",
       "  'amazing',\n",
       "  'library',\n",
       "  'play',\n",
       "  'natural',\n",
       "  'language']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82aa4d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec=Word2Vec(corpus,min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55d707aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2vec.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6784b28a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.7274835e-03,  2.1301603e-03, -8.7354420e-04, -9.3190884e-03,\n",
       "       -9.4281435e-03, -1.4107180e-03,  4.4324086e-03,  3.7040710e-03,\n",
       "       -6.4986944e-03, -6.8730689e-03, -4.9994136e-03, -2.2868442e-03,\n",
       "       -7.2502876e-03, -9.6033188e-03, -2.7436304e-03, -8.3628418e-03,\n",
       "       -6.0388758e-03, -5.6709289e-03, -2.3441387e-03, -1.7069983e-03,\n",
       "       -8.9569995e-03, -7.3519943e-04,  8.1525063e-03,  7.6904297e-03,\n",
       "       -7.2061159e-03, -3.6668323e-03,  3.1185509e-03, -9.5707225e-03,\n",
       "        1.4764380e-03,  6.5244650e-03,  5.7464195e-03, -8.7630628e-03,\n",
       "       -4.5171450e-03, -8.1401607e-03,  4.5955181e-05,  9.2636319e-03,\n",
       "        5.9733056e-03,  5.0673080e-03,  5.0610616e-03, -3.2429171e-03,\n",
       "        9.5521836e-03, -7.3564244e-03, -7.2703888e-03, -2.2653891e-03,\n",
       "       -7.7856064e-04, -3.2161046e-03, -5.9258699e-04,  7.4888230e-03,\n",
       "       -6.9751980e-04, -1.6249418e-03,  2.7443981e-03, -8.3591007e-03,\n",
       "        7.8558037e-03,  8.5361032e-03, -9.5840879e-03,  2.4462652e-03,\n",
       "        9.9049713e-03, -7.6658037e-03, -6.9669201e-03, -7.7365185e-03,\n",
       "        8.3959224e-03, -6.8133592e-04,  9.1444086e-03, -8.1582209e-03,\n",
       "        3.7430834e-03,  2.6350426e-03,  7.4271200e-04,  2.3276759e-03,\n",
       "       -7.4690939e-03, -9.3583753e-03,  2.3545765e-03,  6.1484552e-03,\n",
       "        7.9856869e-03,  5.7358933e-03, -7.7733753e-04,  8.3061643e-03,\n",
       "       -9.3363142e-03,  3.4061312e-03,  2.6675223e-04,  3.8572431e-03,\n",
       "        7.3857834e-03, -6.7251683e-03,  5.5844807e-03, -9.5222257e-03,\n",
       "       -8.0446003e-04, -8.6887386e-03, -5.0986744e-03,  9.2892265e-03,\n",
       "       -1.8582630e-03,  2.9144264e-03,  9.0712784e-03,  8.9381309e-03,\n",
       "       -8.2084350e-03, -3.0123137e-03,  9.8866057e-03,  5.1044296e-03,\n",
       "       -1.5880871e-03, -8.6920215e-03,  2.9615164e-03, -6.6758990e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.wv['python']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f231499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('language', 0.13887985050678253),\n",
       " ('computational', 0.13149003684520721),\n",
       " ('linguistics', 0.0640898123383522),\n",
       " ('library', 0.009391186758875847),\n",
       " ('nltk', -0.05987628176808357)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.wv.most_similar('python')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
